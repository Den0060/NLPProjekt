{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938d8e46-59c6-439f-9ea8-87541c13596d",
   "metadata": {},
   "source": [
    "# Summarizer\n",
    "\n",
    "Erstellt von: Enes Yilmaz, Dennis Waltemathe, Demir Dolovac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8526008-683b-4d67-afd6-acdc6ec950f1",
   "metadata": {},
   "source": [
    "## Einleitung\n",
    "\n",
    "Das Zusammenfassen von Texten ist eine spannende Herausforderung. Besonders bei politischen Reden, wie bei den Bundestagsdebatten gibt es viele Details, was die Generierung von Zusammenfassungen schwierig macht.\n",
    "\n",
    "Um dieses Problem zu lösen, haben wir uns einen passenden Datensatz gesucht, welcher die Bundestagsdebatten von 1949 bis 2021 enthält. Allerdings gab es dabei ein Problem und zwar existierten keine Referenzzusammenfassungen, die als Vergleich oder Traingsdaten genutzt werden konnten.\n",
    "Leider konnten wir auch keinen anderen Datensatz finden, der solche Zusammenfassungen enthält. Deshalb haben wir für einen kleinen zufälligen Teil des Datensatzes, Zusammenfassungen generieren lassen. Diese haben wir in einer neuen CSV-Datei gespeichert, um unser Modell darauf zu trainieren.\n",
    "\n",
    "Im folgenden Bericht werden wir erklären, welche Arten von Zusammenfassungen es gibt, wie wir die Zusammenfassungen erstellt haben, wie das Modell trainiert wurde und welche Ergebnisse wir erzielt haben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5a4b1-149b-426e-b4c1-ab8d8acb5bf8",
   "metadata": {},
   "source": [
    "## Zusammenfassungstypen\n",
    "\n",
    "Es gibt zwei Arten von Textzusammenfassungen, die **abstraktive** und **extraktive** Zusammenfassung.\n",
    "Bei der abstraktiven Zusammenfassung wird die Kernaussage eines Textes mit eigenen Worten zusammengefasst. \n",
    "Das Modell erstellt also eine Zusammenfassung, die nicht 1:1 aus dem ursprünglichen Text entnommen ist. Diese Methode ähnelt der menschlichen Zusammenfassung.\n",
    "Im Gegensatz dazu werden beim extraktiven Vorgehen die wichtigsten Sätze aus dem Originaltext extrahiert und in eine logische Reihenfolge gebracht. Es werden also keine neuen Sätze generiert, sondern nur relevante Sätze des Originaltextes übernommen.\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "Originaltext:<br>\n",
    "*„Die Bundestagsdebatten sind ein zentraler Bestandteil der politischen Entscheidungsfindung in Deutschland. Sie ermöglichen es den Abgeordneten, ihre Positionen und über wichtige Gesetzesvorhaben zu diskutieren.“*\n",
    "\n",
    "Extraktive Zusammenfassung:<br>\n",
    "*„Bundestagsdebatten sind ein zentraler Bestandteil der politischen Entscheidungsfindung in Deutschland, ihre Positionen und über wichtige Gesetzesvorhaben zu diskutieren.“*\n",
    "\n",
    "Abstraktive Zusammenfassungen:<br>\n",
    "*„Bundestagsdebatten dienen der politischen Meinungsbildung und Gesetzesberatung.“*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a09588e-d142-4185-ac9c-855a03fde7e6",
   "metadata": {},
   "source": [
    "## Datensatz\n",
    "\n",
    "Für die Entwicklung und Evaluation unserer Datenmodelle nutzen wir den speeches.csv-Datensatz von Open Discourse [Open Discourse Dokumentation](https://open-discourse.github.io/open-discourse-documentation/1.1.0/index.html)\n",
    ". Dieser Datensatz enthält sämtliche Redebeiträge, die von 1949 bis 2021 im Deutschen Bundestag gehalten wurden, und bietet eine umfangreiche sowie gut strukturierte Grundlage für die Analyse politischer Sprache.\n",
    "\n",
    "Der Datensatz umfasst über 900.000 Reden, ergänzt durch Metadaten wie Wahlperiode, Fraktion, Sprecher sowie das genaue Datum der Rede. <br>\n",
    "Die wichtigsten Merkmale des Datensatzes sind:<br>\n",
    "Klar definierte Strukturen: Die enthaltenen Metadaten ermöglichen eine gezielte Analyse basierend auf politischen Parteien, Legislaturperioden oder individuellen Abgeordneten.<br>\n",
    "Öffentlich zugänglich und gut dokumentiert: Open Discourse stellt eine detaillierte Dokumentation bereit, die eine einfache Nutzung und Reproduzierbarkeit wissenschaftlicher Arbeiten sicherstellt.\n",
    "<br><br>\n",
    "Wir haben jedoch keine Referenzzusammenfassungen in diesem Datensatz, welche für das Trainieren und Testen des Summarizers benötigt werden. Deshalb zeigen wir im Folgenden, wie wir dieses Problem für einen kleinen Teil der speeches.csv gelöst haben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b153de54-a85a-4948-8c89-4d4070a454ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "Zu erst laden wir die speeches.csv:"
   ]
  },
  {
   "cell_type": "code",
   "id": "529327be-47f0-4cb4-9547-a0798e3f7e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:12:32.000874Z",
     "start_time": "2025-02-13T17:12:15.609669Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "csv_datei = \"data_summarizer/speeches.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_datei)\n",
    "\n",
    "speech_contents = df[\"speechContent\"]"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "cd76e6a8-07a7-4458-a195-575200bdcf26",
   "metadata": {},
   "source": [
    "Nun bereiten wir die Originaltexte etwas auf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3ebe52-f86d-419d-97e2-2add9ab032e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"\\n\", \" \").strip()  # Zeilenumbrüche entfernen\n",
    "    text = re.sub(r\"\\{\\d+\\}\", \"\", text)  # Entfernt die {0}, {1}, {2}, etc. aus den Texten\n",
    "    text = text.lower()  # Alles in Kleinbuchstaben umwandeln\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d6bf5-3d54-4750-ab34-16bbc05d661b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Als nächstes filtern wir alle Texte mit mind. 20 Wörtern und wählen zufällig 4000 Texte, welche wir dann in die neue CSV speichern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c497b59-a95a-4a39-b6d4-bd0afb7938b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtert Texte mit mindestens 20 Wörtern\n",
    "filtered_texts = speech_contents[speech_contents.str.split().str.len() >= 20].apply(clean_text)\n",
    "\n",
    "# Zufällig 4000 Texte auswählen\n",
    "random_texts = filtered_texts.sample(n=4000, random_state=42)\n",
    "\n",
    "# Speichert die gefilterten Texte in eine neue CSV-Datei\n",
    "random_texts.to_csv(\"data_summarizer/filtered_speeches.csv\", index=False)   #ACHTUNG: Hier wird dann überschrieben, am besten ein neuen Dateinamen eingeben!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e2da10-694f-45bc-a3cb-ee47290c017e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speechContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>herr präsident! meine sehr verehrten damen und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>das ist eine subjektive bewertung, frau kolleg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>herr kollege czaja, ist ihnen entgangen, daß i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>herr staatsminister, war es nicht, da die verh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aber, herr kollege schiller, wollen sie nicht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>das wort hat nun der innenminister von badenwü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>herr staatssekretär, ist es eigentlich zulässi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>frau abgeordnete, in dem bericht finden sie di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sie müssen sehen, dass der bundesverkehrswegep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>herr staatssekretär, im hinblick darauf, daß g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       speechContent\n",
       "0  herr präsident! meine sehr verehrten damen und...\n",
       "1  das ist eine subjektive bewertung, frau kolleg...\n",
       "2  herr kollege czaja, ist ihnen entgangen, daß i...\n",
       "3  herr staatsminister, war es nicht, da die verh...\n",
       "4  aber, herr kollege schiller, wollen sie nicht ...\n",
       "5  das wort hat nun der innenminister von badenwü...\n",
       "6  herr staatssekretär, ist es eigentlich zulässi...\n",
       "7  frau abgeordnete, in dem bericht finden sie di...\n",
       "8  sie müssen sehen, dass der bundesverkehrswegep...\n",
       "9  herr staatssekretär, im hinblick darauf, daß g..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_csv(\"data_summarizer/filtered_speeches.csv\")\n",
    "\n",
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d551fd-e611-498f-9edf-b55f7c1fa12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Zeilen in alter CSV: 907644\n",
      "Anzahl der Zeilen in neuer CSV: 4000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Anzahl der Zeilen in alter CSV: {len(df)}\")\n",
    "print(f\"Anzahl der Zeilen in neuer CSV: {len(df_new)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02aea5c-3477-4108-a728-3bc76f7bb80a",
   "metadata": {},
   "source": [
    "Anschließend generieren wir für die 4000 Texte jeweils eine Referenzzusammenfassung, dazu verwenden wir **gpt-4o-mini**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2988f13e-f1d7-489e-859b-fc6d6b67b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "openai.api_key = \"KEY\"\n",
    "\n",
    "file_path = \"data_summarizer/filtered_speeches.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def generate_summary_gpt(text):\n",
    "    \"\"\"\n",
    "    Erstellt für jeden Originaltext aus der filtered_speeches.csv eine Referenzzusammenfassung.\n",
    "    :param text: Der Originaltext\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Erstelle eine prägnante, abstraktive Zusammenfassung der folgenden Bundestagsrede, die Zusammenfassung soll kürzer sein als der Originaltext:\n",
    "    \n",
    "    Originaltext: \"{text}\"\n",
    "    \n",
    "    Zusammenfassung: (Bitte beende die Zusammenfassung in vollständigen Sätzen.)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Du bist ein Experte für Textzusammenfassungen.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=250,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei der OpenAI-Anfrage: {e}\")\n",
    "        return \"Fehler bei der Generierung\"\n",
    "\n",
    "summaries = []\n",
    "for text in tqdm(df[\"speechContent\"], desc=\"Generiere abstraktive Zusammenfassungen mit GPT-4\", unit=\"Text\"):\n",
    "    summaries.append(generate_summary_gpt(str(text)))\n",
    "\n",
    "# Neue summaries Spalte für die Referenzzusammenfassungen\n",
    "df[\"summaries\"] = summaries\n",
    "\n",
    "# Datei speichern\n",
    "output_file = \"data_summarizer/filtered_speeches_with_summaries.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Zusammenfassungen gespeichert in '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "735e48ea-780d-4730-8b03-6adaf5c621dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['speechContent', 'summaries'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speechContent</th>\n",
       "      <th>summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>herr präsident! meine sehr verehrten damen und...</td>\n",
       "      <td>In seiner Rede kritisiert der Abgeordnete die ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>das ist eine subjektive bewertung, frau kolleg...</td>\n",
       "      <td>Die Rede betont, dass die Erstellung des Bewer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>herr kollege czaja, ist ihnen entgangen, daß i...</td>\n",
       "      <td>Der Redner weist Herrn Czaja darauf hin, dass ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>herr staatsminister, war es nicht, da die verh...</td>\n",
       "      <td>Der Redner fordert den Staatsminister auf, die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aber, herr kollege schiller, wollen sie nicht ...</td>\n",
       "      <td>Der Redner weist darauf hin, dass die Prognose...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       speechContent   \n",
       "0  herr präsident! meine sehr verehrten damen und...  \\\n",
       "1  das ist eine subjektive bewertung, frau kolleg...   \n",
       "2  herr kollege czaja, ist ihnen entgangen, daß i...   \n",
       "3  herr staatsminister, war es nicht, da die verh...   \n",
       "4  aber, herr kollege schiller, wollen sie nicht ...   \n",
       "\n",
       "                                           summaries  \n",
       "0  In seiner Rede kritisiert der Abgeordnete die ...  \n",
       "1  Die Rede betont, dass die Erstellung des Bewer...  \n",
       "2  Der Redner weist Herrn Czaja darauf hin, dass ...  \n",
       "3  Der Redner fordert den Staatsminister auf, die...  \n",
       "4  Der Redner weist darauf hin, dass die Prognose...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speeches_with_summaries =  pd.read_csv(\"data_summarizer/filtered_speeches_with_summaries.csv\")\n",
    "print(df_speeches_with_summaries.columns)\n",
    "df_speeches_with_summaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd6be5f-b248-41cf-b8d3-42a8d1b4b66f",
   "metadata": {},
   "source": [
    "## Finetuning eines Modells\n",
    "\n",
    "Im Folgenden erklären wir, wie wir Modelle gefinetuned haben. Dazu haben wir vorher die **filtered_speeches** in eine **train.csv** und **test.csv** aufgeteilt (75% train, 25% test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28c4ad-4a61-48e2-9dbd-c8efe4e53162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Lade deine CSV-Datei\n",
    "df = pd.read_csv(\"data_summarizer/filtered_speeches_with_summaries.csv\") \n",
    "\n",
    "# Prüfe, ob die relevanten Spalten vorhanden sind\n",
    "if \"speechContent\" not in df.columns or \"summaries\" not in df.columns:\n",
    "    raise ValueError(\"Die CSV-Datei muss die Spalten 'speechContent' und 'summaries' enthalten.\")\n",
    "\n",
    "# Teile die Daten auf (75% Training, 25% Test)\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Speichere die neuen Dateien\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "print(f\"Trainingsdaten: {len(train_df)} Zeilen\")\n",
    "print(f\"Testdaten: {len(test_df)} Zeilen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853de64-da38-4f87-b28c-af99eeafd2da",
   "metadata": {},
   "source": [
    "Zu erst laden wir die Datensätze und legen die Teilmengen für das Training und Testen fest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4611cacc-742a-4354-a22b-c2c12a5e0696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "dataset = load_dataset(\"csv\", data_files={\"train\": \"data_summarizer/train.csv\", \"test\": \"data_summarizer/test.csv\"})\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796b7d54-22f7-4701-aabe-ab80de8f9bd4",
   "metadata": {},
   "source": [
    "Als nächstes laden wir den AutoTokenizer für ein vortrainiertes Modell und definieren eine Funktion, die Redebeiträge (`speechContent`) und Zusammenfassungen (`summaries`) tokenisiert. Dabei werden die Eingaben auf eine maximale Länge gebracht, mit Padding ergänzt und abgeschnitten. Anschließend mappen wir die Funktion auf den gesamten Datensatz, um tokenisierte Trainingsdaten zu erstellen.\n",
    "\n",
    "Wir möchten das Modell [t5-small](https://huggingface.co/google-t5/t5-small) finetunen, welches bereits für die deutsche Sprache bzw. das Zusammenfassen deutscher Texte optimiert wurde. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "344aac2a-0e01-482c-9dbb-a5db054d8c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf9129e02cb40f59fb2298f064e4660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"t5-small\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"speechContent\"], \n",
    "        max_length=512, \n",
    "        padding=\"max_length\",  \n",
    "        truncation=True\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"summaries\"], \n",
    "        max_length=150, \n",
    "        padding=\"max_length\",  # Auch hier Padding auf die maximale Länge\n",
    "        truncation=True\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41717c75-4e34-4574-a052-8a239262165e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221960f3-4e47-44fd-bbde-d900f026a1ce",
   "metadata": {},
   "source": [
    "Nun trainieren wir das Modell, dabei definieren wir die Trainingsparameter und erstellen einen Trainer, die das Modell fintuned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "123bc145-6d24-480b-a754-456373982392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipykernel_104/3582634350.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='752' max='752' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [752/752 07:49, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.100400</td>\n",
       "      <td>1.725781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.919500</td>\n",
       "      <td>1.549682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.741400</td>\n",
       "      <td>1.480842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.688300</td>\n",
       "      <td>1.445464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.576100</td>\n",
       "      <td>1.422272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.609400</td>\n",
       "      <td>1.410084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.542100</td>\n",
       "      <td>1.402987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.618900</td>\n",
       "      <td>1.400709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=752, training_loss=1.9296705386740096, metrics={'train_runtime': 473.1722, 'train_samples_per_second': 50.721, 'train_steps_per_second': 1.589, 'total_flos': 3248203235328000.0, 'train_loss': 1.9296705386740096, 'epoch': 8.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    do_train=True,\n",
    "    do_eval=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17818d40-aa1a-4f2d-81f6-25a72ff96bf2",
   "metadata": {},
   "source": [
    "Anschließend speichern wir das Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "492fcf43-589e-46e6-a3df-a1db73185f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5_finetuned/summarizer_model/tokenizer_config.json',\n",
       " 't5_finetuned/summarizer_model/special_tokens_map.json',\n",
       " 't5_finetuned/summarizer_model/spiece.model',\n",
       " 't5_finetuned/summarizer_model/added_tokens.json',\n",
       " 't5_finetuned/summarizer_model/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"models_summarizer/t5_finetuned_abgabe_neu/summarizer_model\")  #Neu wurde hinzugefügt, damit das bereits trainierte Modell nicht überschrieben wird\n",
    "tokenizer.save_pretrained(\"models_summarizer/t5_finetuned_abgabe_neu/summarizer_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f882ac3c-0d87-485a-9ae6-95d3bc5a90bf",
   "metadata": {},
   "source": [
    "## ROUGE-Score\n",
    "Zur Bewertung der Modelle haben wir den ROUGE-Score (Recall-Oriented Unterstudy for Gisting Evaluation) verwendet, dies ist eine Metrik, welche zur Bewertung der Qualität von autmatisch generierter Texte wie zum Beispiel Zusammenfassungen verwendet wird. \n",
    "Der ROUGE-Score vergleicht die vom Modell erzeugte Zusammenfassung mit einer Referenzzusammenfassung, indem er die Übereinstimmungen von n-Grammen (Wortsequenzen) misst. \n",
    "So weist ein höher ROUGE-Score auf eine höhere Ähnlichkeit zwischen der generierten Zusammenfassung und der Referenzzusammenfassung hin.\n",
    "\n",
    "Um die Qualität der generierten Zusammenfassungen genauer bewerten zu können, gibt es verschiedene ROUGE-Varianten, welche verschiedene Teile der inhaltlichen Übereinstimmung berücksichtigen:\n",
    "\n",
    "**<u>ROUGE-N</u>** <br>\n",
    "Diese Variante misst Überlappung von n-Grammen (Sequenzen von n aufeinanderfolgenden Wörtern) zwischen der generierten und Referenzzusammenfassung.\n",
    "So würde beispielsweise der ROUGE-1 Score die Übereinstimmung einzelner Wörter (Unigramme) messen und der ROUGE-2 Score die Übereinstimmung von Wortpaaren (Bigramme).\n",
    "\n",
    "Beispiel:<br>\n",
    "Referenz: *„Die Katze sitzt auf dem Stuhl“*<br>\n",
    "Generiert: *„Der Hund schläft auf dem Stuhl“*\n",
    "\n",
    "Die gemeinsamen Unigramme wären hier: [„auf“, „dem“, „Stuhl“] und die gemeinsamen Bigramme wären: [„auf dem“, „dem Stuhl“]\n",
    "\n",
    "**<u>ROUGE-L</u>** <br>\n",
    "Eine weitere Variante basiert auf der längsten gemeinsamen Teilsequenz (LCS). Hier wird die längste gemeinsame Teilsequenze der beiden Zusammenfassungen gemessen, dabei müssen die Wörter nicht unbedingt nebeneinander stehen.\n",
    "\n",
    "Beispiel:<br>\n",
    "Referenz: *„Das Auto ist schnell und groß.“*<br>\n",
    "Generiert: *„Das rote Auto fährt schnell.“*\n",
    "\n",
    "Die längste gemeinsame Teilsequenz wäre hier „Das Auto schnell“.\n",
    "\n",
    "**<u>ROUGE-S</u>** <br>\n",
    "Die letzte ROUGE-Score Variante misst die Übereinstimmung von Skip-Bigrammen, also Wortpaaren die in einer Reihenfolge vorkommen, aber nicht direkt nebeneinander stehen, dies ermöglicht es Wortpaare aus dem Referenztext zu identifizieren, die auch in der generierten Zusammenfassung vorkommen, dadurch wird der inhaltliche Kontext eines Textes erfasst, selbst wenn Wörter durch andere Begriffe getrennt ist.\n",
    "\n",
    "Beispiel: <br>\n",
    "Referenz: *„Die Katze ist auf der Matte.“* <br>\n",
    "Generiert: *„Die graue Katze springt herum.“*\n",
    "\n",
    "Im ROUGE-N würde es keine Überlappungen geben, doch mittels Skip-Bigrammen würden hier „Die Katze“ und „Die graue Katze“ übereinstimmen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f2187e-4813-491b-bdef-c1a707ee0791",
   "metadata": {},
   "source": [
    "## Berechnung der ROUGE-Scores\n",
    "\n",
    "Die Berechnung basiert auf den Konzepten der **Recall**, **Precsision** und **F1-Score**.\n",
    "So wird der Recall durch den Anteil der überlappenden Wörtern aus der Referenz mit der generierten Zusammenfassung und der Gesamtanzahl der n-Gramme der Referenzzusammenfassung berechnet:\n",
    "\n",
    "$$recall = \\frac{gemeinsame\\ n-Gramme}{n-Gramme\\ in\\ der\\ Referenzzusammenfassung} $$\n",
    "\n",
    "Die Precision wird durch den Anteil der gemeinsamen n-Gramme und mit der Gesamtzahl der n-Gramme der generierten Zusammenfassung berechnet:\n",
    "\n",
    "$$precision = \\frac{gemeinsame\\ n-Gramme}{n-Gramme\\ in\\ der\\ generierten\\ Zusammenfassung} $$\n",
    "\n",
    "Um ein Gleichgewicht zwischen Recall und Precision zu finden wird der F1-Score folgendermaßen berechnet:\n",
    "\n",
    "$$F1 = 2\\ x\\ \\frac{precision\\ x\\ recall}{precision\\ +\\ recall} $$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023b0ea5-e190-497d-82bb-ceb3cdff3a44",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Finetuned vs. Original\n",
    "\n",
    "Nun vergleichen wir das originale Modell und das finedtuned Modell, dazu verwenden wir den soeben beschriebenen ROUGE-Score. Dafür laden wir uns zuerst die Metrik runter:"
   ]
  },
  {
   "cell_type": "code",
   "id": "0a8c866d-48ea-48b1-af97-9916508cd49f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-13T13:31:29.950013Z",
     "start_time": "2025-02-13T13:31:17.838050Z"
    }
   },
   "source": [
    "!pip install rouge-score\n",
    "#https://thepythoncode.com/article/calculate-rouge-score-in-python#setting-up-the-environment-for-python-implementation"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting absl-py (from rouge-score)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from nltk->rouge-score) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from nltk->rouge-score) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from nltk->rouge-score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (pyproject.toml): started\n",
      "  Building wheel for rouge-score (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=25025 sha256=140f2d7799bfd8e9f727c3be9a35ecf7053a3a037a378822f3d8af562a70d1fd\n",
      "  Stored in directory: c:\\users\\dolov\\appdata\\local\\pip\\cache\\wheels\\85\\9d\\af\\01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: absl-py, rouge-score\n",
      "Successfully installed absl-py-2.1.0 rouge-score-0.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "864a6bdc-1513-46c5-ac13-b41587888b9c",
   "metadata": {},
   "source": [
    "Nun berechnen wir den ROUGE-Score, dazu wird ein Text aus der test.csv verwendet und von beiden Modellen zusammengefasst. Anschließend werden beide Zusammenfassungen mit der Referenzzusammenfassung verglichen, was dann die ROUGE-Scores für Presicion, Recall und F1-Score liefert:"
   ]
  },
  {
   "cell_type": "code",
   "id": "825a00b8-f4ce-476b-9dd2-82b414070f0b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-13T13:33:04.528905Z",
     "start_time": "2025-02-13T13:32:59.355455Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer\n",
    "import pandas as pd\n",
    "\n",
    "df_test_csv = pd.read_csv(\"data_summarizer/test.csv\")\n",
    "\n",
    "\n",
    "originaltext = df_test_csv[\"speechContent\"][0]\n",
    "referenztext = df_test_csv[\"summaries\"][0]\n",
    "\n",
    "# Finegetuntes Modell\n",
    "fn_summarizer = pipeline(\"summarization\", model=\"models_summarizer/t5_finetuned_abgabe/summarizer_model\", tokenizer=\"models_summarizer/t5_finetuned_abgabe/summarizer_model\")\n",
    "fn_zusammenfassung = fn_summarizer(originaltext, max_length=150, min_length=50, do_sample=False)[0][\"summary_text\"]\n",
    "\n",
    "# Originales Modell\n",
    "orig_summarizer = pipeline(\"summarization\", model=\"t5-small\", tokenizer=\"t5-small\")\n",
    "orig_zusammenfassung = orig_summarizer(originaltext, max_length=150, min_length=50, do_sample=False)[0][\"summary_text\"]\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# ROUGE für finegetuntes Modell\n",
    "fn_rouge = scorer.score(referenztext, fn_zusammenfassung)\n",
    "\n",
    "# ROUGE für Basismodell\n",
    "orig_rouge = scorer.score(referenztext, orig_zusammenfassung)\n",
    "\n",
    "print(\"Fine-tuned Modell ROUGE Scores:\")\n",
    "print(f\"ROUGE-1: {fn_rouge['rouge1']}\")\n",
    "print(f\"ROUGE-2: {fn_rouge['rouge2']}\")\n",
    "print(f\"ROUGE-L: {fn_rouge['rougeL']}\")\n",
    "\n",
    "print(\"\\nOriginales Modell ROUGE Scores:\")\n",
    "print(f\"ROUGE-1: {orig_rouge['rouge1']}\")\n",
    "print(f\"ROUGE-2: {orig_rouge['rouge2']}\")\n",
    "print(f\"ROUGE-L: {orig_rouge['rougeL']}\")\n",
    "\n",
    "print()\n",
    "print(f\"Originaltext: {originaltext}\\n\")\n",
    "print(f\"Referenzzusammenfassung: {referenztext}\\n\")\n",
    "print(f\"Originales Modell: {orig_zusammenfassung}\\n\")\n",
    "print(f\"FN-Modell: {fn_zusammenfassung}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Your max_length is set to 150, but your input_length is only 94. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n",
      "Device set to use cpu\n",
      "Your max_length is set to 150, but your input_length is only 94. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Modell ROUGE Scores:\n",
      "ROUGE-1: Score(precision=0.6774193548387096, recall=0.7777777777777778, fmeasure=0.7241379310344828)\n",
      "ROUGE-2: Score(precision=0.4666666666666667, recall=0.5384615384615384, fmeasure=0.5)\n",
      "ROUGE-L: Score(precision=0.5806451612903226, recall=0.6666666666666666, fmeasure=0.6206896551724138)\n",
      "\n",
      "Originales Modell ROUGE Scores:\n",
      "ROUGE-1: Score(precision=0.6176470588235294, recall=0.7777777777777778, fmeasure=0.6885245901639345)\n",
      "ROUGE-2: Score(precision=0.45454545454545453, recall=0.5769230769230769, fmeasure=0.5084745762711863)\n",
      "ROUGE-L: Score(precision=0.5294117647058824, recall=0.6666666666666666, fmeasure=0.5901639344262295)\n",
      "\n",
      "Originaltext: herr kollege berger, meine antwort ist kurz; sie lautet nein. die dislozierung der luftlandetruppen des warschauer paktes ist nach dem erkenntnisstand der bundesregierung nach wie vor unverändert. es gibt auch keine anzeichen für mögliche veränderungen außerhalb des mbfr-reduzierungsraums.\n",
      "\n",
      "Referenzzusammenfassung: Die Bundesregierung sieht keine Veränderungen bei der Dislozierung der Luftlandetruppen des Warschauer Paktes und erkennt auch keine Anzeichen für Änderungen außerhalb des MBFR-Reduzierungsraums.\n",
      "\n",
      "Originales Modell: die dislozierung der luftlandetruppen des warschauer paktes ist nach dem erkenntnisstand der bundesregierung nach wie vor unverändert. es gibt auch keine anzeichen für mögliche veränderungen außerhalb des mbfr-reduzierungsraums.\n",
      "\n",
      "FN-Modell: kollege berger hebt die Dislozierung der Luftlandetruppen des warschauer paktes nach dem Erkenntnisstand der Bundesregierung hervor und gibt keine Anzeichen für mögliche Veränderungen außerhalb des mbfr-reduzierungsraums.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "16a43ec9-0720-4003-931a-66225efe1ca3",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "**Vergleich mit anderen Modellen:**\n",
    "\n",
    "Dazu werden die finegetunten Modelle mit den originalen Modellen vergleichen. Die finegetunten Modelle sind unter (`mt5-small/summarizer_model`) (`t5_finetuned_abgabe/summarizer_model`) und (`bert_finetuned/summarizer_model`) zu finden.\n",
    "\n",
    "Originaltext: df_test_csv[\"speechContent\"][622]\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "\n",
    "<!-- Erste Tabelle -->\n",
    "<div>\n",
    "<p style=\"text-align: center;\"><strong>Finetuned Modelle</strong></p>\n",
    "<table>\n",
    "<tr>\n",
    "<th>ROUGE-SCORE</th><th>mt5-small</th><th>t5-small</th><th>mbart-large-50</th>\n",
    "</tr>\n",
    "<tr><td>R1-Precision</td><td>0.4848</td><td>0.6</td><td>0.7096</td></tr>\n",
    "<tr><td>R1-Recall</td><td>0.5925</td><td>0.5555</td><td>0.4313</td></tr>\n",
    "<tr><td>R1-F1</td><td>0.5333</td><td>0.5769</td><td>0.5365</td></tr>\n",
    "<tr><td>R2-Precision</td><td>0.3125</td><td>0.3333</td><td>0.3666</td></tr>\n",
    "<tr><td>R2-Recall</td><td>0.3846</td><td>0.3076</td><td>0.22</td></tr>\n",
    "<tr><td>R2-F1</td><td>0.3448</td><td>0.32</td><td>0.2749</td></tr>\n",
    "<tr><td>RL-Precision</td><td>0.3636</td><td>0.32</td><td>0.6129</td></tr>\n",
    "<tr><td>RL-Recall</td><td>0.4444</td><td>0.2962</td><td>0.3725</td></tr>\n",
    "<tr><td>RL-F1</td><td>0.3999</td><td>0.3076</td><td>0.4634</td></tr>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "<!-- Zweite Tabelle -->\n",
    "<div>\n",
    "<p style=\"text-align: center;\"><strong>Originale Modelle</strong></p>\n",
    "<table>\n",
    "<tr>\n",
    "<th>ROUGE-SCORE</th><th>mt5-small</th><th>t5-small</th><th>mbart-large-50</th>\n",
    "</tr>\n",
    "<tr><td>R1-Precision</td><td>0.35</td><td>0.56</td><td>0.4</td></tr>\n",
    "<tr><td>R1-Recall</td><td>0.2592</td><td>0.5185</td><td>0.7450</td></tr>\n",
    "<tr><td>R1-F1</td><td>0.2978</td><td>0.5384</td><td>0.5205</td></tr>\n",
    "<tr><td>R2-Precision</td><td>0.1578</td><td>0.375</td><td>0.2978</td></tr>\n",
    "<tr><td>R2-Recall</td><td>0.1153</td><td>0.3461</td><td>0.56</td></tr>\n",
    "<tr><td>R2-F1</td><td>0.1333</td><td>0.3599</td><td>0.3888</td></tr>\n",
    "<tr><td>RL-Precision</td><td>0.35</td><td>0.52</td><td>0.3789</td></tr>\n",
    "<tr><td>RL-Recall</td><td>0.2592</td><td>0.4814</td><td>0.7058</td></tr>\n",
    "<tr><td>RL-F1</td><td>0.2978</td><td>0.5</td><td>0.4931</td></tr>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204abbd7-2d34-4423-80a7-a23e8d3d93c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Vergleich mit anderen Modellen:**\n",
    "\n",
    "Originaltext: df_test_csv[\"speechContent\"][0]<br>\n",
    "\n",
    "**Was man hier sehen kann ist, dass besonders das optimierte mt5-small Modell um einiges besser ist als das originale mt5-small Modell.**\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "\n",
    "<!-- Erste Tabelle -->\n",
    "<div>\n",
    "<p style=\"text-align: center;\"><strong>Finetuned Modelle</strong></p>\n",
    "<table>\n",
    "<tr>\n",
    "<th>ROUGE-SCORE</th><th>mt5-small</th><th>t5-small</th><th>mbart-large-50</th>\n",
    "</tr>\n",
    "<tr><td>R1-Precision</td><td>0.6060</td><td>0.6774</td><td>0.6363</td></tr>\n",
    "<tr><td>R1-Recall</td><td>0.7407</td><td>0.7777</td><td>0.7777</td></tr>\n",
    "<tr><td>R1-F1</td><td>0.6666</td><td>0.7241</td><td>0.7</td></tr>\n",
    "<tr><td>R2-Precision</td><td>0.4375</td><td>0.4666</td><td>0.4687</td></tr>\n",
    "<tr><td>R2-Recall</td><td>0.5384</td><td>0.5384</td><td>0.5769</td></tr>\n",
    "<tr><td>R2-F1</td><td>0.4827</td><td>0.5</td><td>0.5172</td></tr>\n",
    "<tr><td>RL-Precision</td><td>0.5151</td><td>0.5806</td><td>0.5757</td></tr>\n",
    "<tr><td>RL-Recall</td><td>0.6296</td><td>0.6666</td><td>0.7037</td></tr>\n",
    "<tr><td>RL-F1</td><td>0.5666</td><td>0.6206</td><td>0.6333</td></tr>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "<!-- Zweite Tabelle -->\n",
    "<div>\n",
    "<p style=\"text-align: center;\"><strong>Originale Modelle</strong></p>\n",
    "<table>\n",
    "<tr>\n",
    "<th>ROUGE-SCORE</th><th>mt5-small</th><th>t5-small</th><th>mbart-large-50</th>\n",
    "</tr>\n",
    "<tr><td>R1-Precision</td><td>0.1</td><td>0.6176</td><td>0.4772</td></tr>\n",
    "<tr><td>R1-Recall</td><td>0.1111</td><td>0.7777</td><td>0.7777</td></tr>\n",
    "<tr><td>R1-F1</td><td>0.1052</td><td>0.6885</td><td>0.5915</td></tr>\n",
    "<tr><td>R2-Precision</td><td>0.0</td><td>0.4545</td><td>0.3488</td></tr>\n",
    "<tr><td>R2-Recall</td><td>0.0</td><td>0.5769</td><td>0.5769</td></tr>\n",
    "<tr><td>R2-F1</td><td>0.0</td><td>0.5084</td><td>0.4347</td></tr>\n",
    "<tr><td>RL-Precision</td><td>0.1</td><td>0.5294</td><td>0.4090</td></tr>\n",
    "<tr><td>RL-Recall</td><td>0.1111</td><td>0.6666</td><td>0.6666</td></tr>\n",
    "<tr><td>RL-F1</td><td>0.1052</td><td>0.5901</td><td>0.5070</td></tr>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b78d9-b1d5-4bde-8f56-9fd22768cdff",
   "metadata": {},
   "source": [
    "Aber nicht immer schneidet das finetuned Modell besser oder viel besser ab:\n",
    "\n",
    "**df_test_csv[\"speechContent\"][255]**\n",
    "\n",
    "Fine-tuned Modell ROUGE Scores:<br>\n",
    "ROUGE-1: Score(precision=0.3333333333333333, recall=0.4074074074074074, fmeasure=0.36666666666666664)<br>\n",
    "ROUGE-2: Score(precision=0.125, recall=0.15384615384615385, fmeasure=0.13793103448275862)<br>\n",
    "ROUGE-L: Score(precision=0.24242424242424243, recall=0.2962962962962963, fmeasure=0.26666666666666666)<br>\n",
    "\n",
    "Originales Modell ROUGE Scores:<br>\n",
    "ROUGE-1: Score(precision=0.43333333333333335, recall=0.48148148148148145, fmeasure=0.456140350877193)<br>\n",
    "ROUGE-2: Score(precision=0.13793103448275862, recall=0.15384615384615385, fmeasure=0.14545454545454548)<br>\n",
    "ROUGE-L: Score(precision=0.26666666666666666, recall=0.2962962962962963, fmeasure=0.28070175438596495)<br>\n",
    "\n",
    "Originaltext:<br>\n",
    "ich habe das erst vor wenigen tagen in einem umfangreichen artikel in der zeitung „die welt\" gemacht. wir machen das in vielen fachzeitschriften. je nach bedarf wird dies fortgesetzt.\n",
    "\n",
    "Referenzzusammenfassung:<br>\n",
    "Zusammenfassung: \"Vor kurzem habe ich einen ausführlichen Artikel in der 'Welt' veröffentlicht. Wir publizieren regelmäßig in Fachzeitschriften und setzen dies je nach Bedarf fort.\"\n",
    "\n",
    "Originales Modell:<br>\n",
    "ich habe das erst vor wenigen tagen in einem umfangreichen artikel in der zeitung „die welt\" gemacht. je nach bedarf wird dies dies fortgesetzt. ich mache das in vielen fachzeitschriften.\n",
    "\n",
    "FN-Modell:<br>\n",
    "in der Zeitung „die welt“ wird ein umfangreiches Artikel erstellt, das in vielen fachzeitschriften gedruckt wird. Die Fortsetzungen werden nach Bedarf gesetzt. Die Zeitschriften werden in der aktuellen Zeitschrift „die Welt“ veröffentlicht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b5aad-e762-478b-8d1f-eafe0e55ac1f",
   "metadata": {},
   "source": [
    "Mögliche Gründe dafür können sein:\n",
    "- **Mangel an Daten**: Mit zu wenigen Trainingsdaten kann das Modell nicht ausreichend lernen und hat Schwierigkeiten bei der Generalisierung.\n",
    "- **Qualität der Referenzzusammenfassungen**: Da die Referenzzusammenfassungen keine menschlichen Zusammenfassungen sind, sondern generierte, könnten sie weniger genau oder verständlich sein, was die Bewertung des Modells beeinträchtigen kann \n",
    "- **Overfitting**: Einige Testdaten ähneln vielleicht den Trainingsdaten, und das Modell könnte sich zu stark an diese spezifischen Beispiele anpassen, wodurch die Generalisierungsfähigkeit auf neue, unterschiedliche Daten eingeschränkt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b7a9a-083a-458e-942e-c3f85fcc4c20",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bemerkung\n",
    "Was uns aufgefallen ist, dass unser optimiertes (`t5-small`) Modell auch für einige Texte bessere Zusammenfassungen erstellt als das originale Modell, selbst wenn der Inhalt nicht viel oder garnichts mit dem trainierten Kontext der Datensätze zu tun hat.\n",
    "\n",
    "*Ein Beispiel verdeutlicht diesen Unterschied:*\n",
    "\n",
    "Originaltext:<br>\n",
    "Die Text-Extraction (englisch text extraction auch englisch keyphrase extraction) bzw. Textextrahierung ist eine Methode zur automatischen Zusammenfassung eines Textes mit Hilfe computerlinguistischer Techniken. Dabei werden Teile eines Textes – zum Beispiel Sätze oder ganze Abschnitte – mittels statistischer und/oder heuristischer Methoden bezüglich ihrer Wichtigkeit oder Relevanz bewertet. Diese scores of importance dienen als Grundlage für die Entscheidung, welche Teile (\"keyphrases\") extrahiert und zu einem kürzeren Text zusammengestellt werden, der dann einen Überblick über die Inhalte des Originaltextes bietet und in der Regel als extract oder abstract bezeichnet wird.\n",
    "\n",
    "Nach Karen Spärck Jones (1999) haben die mit dieser Methode produzierten Zusammenfassungen den Nachteil, dass sie zumeist wenig kohärent und somit nur schlecht lesbar und unter Umständen sogar unverständlich sind. Andererseits ist diese Methode und ihre Varianten vermutlich einfacher in automatischen Systemen zu modellieren. Beispiele dafür sind die Systeme von Hans Peter Luhn (1959) (Extraktionsalgorithmus nach Luhn) und Edmundson (1969) und die Ansätze von Rath et al. (1961) und Brandow et al. (1995).\n",
    "\n",
    "Zusammenfassung des ungetunten Modells (T5-Small, pretrained):<br>\n",
    "„Dabei werden Teile eines Textes mittels statistischer und/oder heuristischer Techniken bewertet. Diese Scores of Importance dienen als Grundlage für die Entscheidung, welche Teile (Keyphrases) extrahiert und zu einem kürzeren Text zusammengestellt werden, der dann einen Überblick über die Inhalte des Originaltextes bietet und in der Regel als Extract oder Abstract bezeichnet wird.“\n",
    "\n",
    "Zusammenfassung des getunten Modells:<br>\n",
    "„Text-Extraction (englisch text extraction) bzw. Textextrahierung ist eine Methode zur automatischen Zusammenfassung von Texten mit Hilfe computerlinguistischer Techniken. Teile einer Texte werden mittels statistischer und/oder heuristischer Methoden bewertet, die einen Überblick über die Inhalte des Originaltextes bieten und in der Regel als Extract oder Abstract bezeichnet werden. Nach Karen Spärck Jones (1999) hat die Methode erstellt Zusammenfassungen, die wenig kohärent sind und die Ansätze von Rath et al.“\n",
    "\n",
    "Der Unterschied ist deutlich:<br> Das vortrainierte Modell produziert eine eher generische und redundante Zusammenfassung, während das getunte Modell die Begriffe präziser einordnet, den Kontext besser versteht und kohärentere Sätze formuliert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a070a-bbf5-4521-99b5-8322fba685e7",
   "metadata": {},
   "source": [
    "## Vergleich: extr. und abstr. Summarizer\n",
    "\n",
    "Für die extraktive Textzusammenfassung setzen wir unter anderem die Python-Bibliothek Sumy ein. Die Stärke von Sumy liegt in seiner einfachen Implementierung und der Möglichkeit, unterschiedliche Methoden für extraktive Zusammenfassungen zu testen. Dies macht es zu einem idealen Werkzeug für unsere Analyse von Redebeiträgen aus dem Open-Discourse-Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "id": "56ccc459-7676-4d8c-9689-9f145ae0482f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-13T13:34:28.422978Z",
     "start_time": "2025-02-13T13:34:28.419467Z"
    }
   },
   "source": "text = speech_contents[609]",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "5d5c7b0a-0bc3-4d05-87d0-55656c816ae9",
   "metadata": {},
   "source": [
    "Als Nächstes laden wir die `punkt`-Ressource von **NLTK**, die für die Tokenisierung von Sätzen und Wörtern benötigt wird.  \n",
    "Diese erlaubt es uns, Texte in einzelne Wörter oder Sätze zu zerlegen."
   ]
  },
  {
   "cell_type": "code",
   "id": "98b05523-66a6-4828-a4b1-aa1decea343a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-13T13:38:54.280910Z",
     "start_time": "2025-02-13T13:38:53.233007Z"
    }
   },
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dolov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dolov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "4eeb44f3-60c8-40cf-9461-8431bed9e2f9",
   "metadata": {},
   "source": [
    "Als Nächstes verwenden wir **Sumy**, um eine extraktive Zusammenfassung mit dem **LexRank-Algorithmus** zu erstellen.  \n",
    "LexRank ist ein graphbasiertes Verfahren zur Bestimmung der wichtigsten Sätze in einem Text."
   ]
  },
  {
   "cell_type": "code",
   "id": "aa7da8de-58cb-407c-af2d-5936e6a97a2d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-13T13:33:47.917893Z",
     "start_time": "2025-02-13T13:33:22.298277Z"
    }
   },
   "source": [
    "!pip install sumy"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting docopt<0.7,>=0.6.1 (from sumy)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting breadability>=0.1.20 (from sumy)\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from sumy) (2.32.3)\n",
      "Collecting pycountry>=18.2.23 (from sumy)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from sumy) (3.9.1)\n",
      "Collecting chardet (from breadability>=0.1.20->sumy)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting lxml>=2.0 (from breadability>=0.1.20->sumy)\n",
      "  Downloading lxml-5.3.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from nltk>=3.0.2->sumy) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from requests>=2.7.0->sumy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from requests>=2.7.0->sumy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from requests>=2.7.0->sumy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from requests>=2.7.0->sumy) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dolov\\onedrive\\desktop\\phyton_udemy\\abschnitt6funktionen\\.venv\\lib\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.6)\n",
      "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.3 MB 2.8 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.8/6.3 MB 2.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.3/6.3 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.1/6.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.1/6.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.9/6.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading lxml-5.3.1-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.4/3.8 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Building wheels for collected packages: breadability, docopt\n",
      "  Building wheel for breadability (pyproject.toml): started\n",
      "  Building wheel for breadability (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21801 sha256=1c31efa02a9cff387f8835d0e2e8bc2d64adcf66f7a9dd8c43029a8ac0df4dd3\n",
      "  Stored in directory: c:\\users\\dolov\\appdata\\local\\pip\\cache\\wheels\\32\\99\\64\\59305409cacd03aa03e7bddf31a9db34b1fa7033bd41972662\n",
      "  Building wheel for docopt (pyproject.toml): started\n",
      "  Building wheel for docopt (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13822 sha256=6358a4363e46ef7884f7a07852455f079360746daed3874b33e978be0e64e81b\n",
      "  Stored in directory: c:\\users\\dolov\\appdata\\local\\pip\\cache\\wheels\\1a\\bf\\a1\\4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "Successfully built breadability docopt\n",
      "Installing collected packages: docopt, pycountry, lxml, chardet, breadability, sumy\n",
      "Successfully installed breadability-0.1.20 chardet-5.2.0 docopt-0.6.2 lxml-5.3.1 pycountry-24.6.1 sumy-0.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "47e5ea0f-33fb-41dd-bf13-b49d31847b17",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-13T13:38:58.650650Z",
     "start_time": "2025-02-13T13:38:58.527896Z"
    }
   },
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "\n",
    "\n",
    "# Parser und Tokenizer\n",
    "parser = PlaintextParser.from_string(text, Tokenizer(\"german\"))\n",
    "summarizer = LexRankSummarizer()\n",
    "\n",
    "# Zusammenfassung erstellen (z. B. 3 Sätze)\n",
    "summary = summarizer(parser.document, 3)\n",
    "\n",
    "extractive_sum=\"\"\n",
    "for sentence in summary:\n",
    "    extractive_sum += str(sentence)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "b761f09d-fb55-4db5-889a-9ae15202805a",
   "metadata": {},
   "source": [
    "Für die abstraktive Textzusammenfassung nutzen wir das vortrainierte Modell t5-small. Die Stärke von T5 liegt in seiner Fähigkeit, den Inhalt eines Textes neu zu formulieren und prägnant wiederzugeben, anstatt lediglich wichtige Sätze auszuwählen. Dies macht es zu einem leistungsfähigen Werkzeug für unsere Analyse von Redebeiträgen aus dem Open-Discourse-Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "id": "ae4a66fe-a06c-4541-a931-96b6b11c3f81",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-13T13:39:15.547918Z",
     "start_time": "2025-02-13T13:39:04.185394Z"
    }
   },
   "source": [
    "from transformers import pipeline, T5Tokenizer\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"models_summarizer/t5_finetuned_abgabe/summarizer_model\", tokenizer=\"models_summarizer/t5_finetuned_abgabe/summarizer_model\")\n",
    "\n",
    "abstractive_sum = summarizer(text, max_length=250, min_length=50, do_sample=False)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "59e355da-230c-4f3e-8d7d-331557ddb6e1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-13T13:39:15.557076Z",
     "start_time": "2025-02-13T13:39:15.552985Z"
    }
   },
   "source": [
    "print(\"Original text: \", text)\n",
    "print(\"Extraktive Zusammenfassung: \", extractive_sum)\n",
    "print()\n",
    "print(\"Abstraktive Zusammenfassung: \", abstractive_sum)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:  Nein; ich, sagte: bei der bekannten Loyalität rechnete ich damit, daß Sie das nicht täten, Herr Präsident.\n",
      "Aber nun zu dem Thema selbst. Ich möchte darauf aufmerksam machen, daß nach meiner Meinung das Berlin-Thema, das wir hier nun verschiedentlich erörtert haben, bisher etwas zu kasuistisch angefaßt worden ist. Man hat heute vom Herrn Finanzminister eine Zusammenfassung verschiedener Hilfsmaßnahmen gehört, allerdings nicht so erschöpfend - oder sollte es mir entgangen sein? -, daß man von allem, auch zum Beispiel von der Portoabgabe ein zahlenmäßiges Ergebnis hätte hören können. Das ist aber nur die eine Seite. Das betrifft nämlich die Maßnahmen, die zum Schutz und zur Unterstützung der kämpfenden Berliner Bevölkerung beschlossen worden sind. Es bedürfte einmal einer systematischen Zusammenstellung, damit wir übersehen, was bisher insgesamt, wie auch was eus den einzelnen Quellen nach Berlin geflossen ist.\n",
      "Wichtiger scheint mir die andere Seite zu sein. Wir leiden -- so scheint es mir -- ein wenig daran, daß wir die ganze Anlegenheit Berlin am Symptom kurieren wollen, ohne daß ein einheitlicher, großzügiger Plan vorliegt, nach welchem man vorgehen kann und in Zukunft auch vorgehen will. Man muß eimal die Notwendigkeiten von Berlin und ebenso demgegenüber die eigenen Bedürfnisse feststellen und dann abwägen; denn schließlich gibt es nicht nur in Berlin Arbeitslose, sondern leider Gottes ist die Arbeitslosigkeit eine Angelegenheit, die auch im Westen bei den bekanntermaßen 1,8 Millionen direkt Betroffenen die schwersten Sorgen hervorruft. Bekanntlich gibt es nicht bloß in Berlin, sondern auch im Westen Ausgebombte. Dazu haben wir noch Flüchtlinge und außerdem die, die alltäglich über die Zonengrenze von der russisch besetzten Zone her durchsickern. Es muß doch einmal ein Gesamtbild gegeben und ein Plan aufgestellt werden, um bei/ des miteinander abzustimmen.\n",
      "Auch für die Reorganisation der Berliner Wirtschaft und für die Abstimmung ihrer Leistungen mit den Bedürfnissen des Westens muß ein Plan gemacht werden. Wenn wir nur Geld dahin leiten, besteht die Gefahr, daß dieses dort durchaus fehl investiert wird, so daß es weder der Berliner noch unserer Wirtschaft nutzt, sondern daß womöglich hinterher die beiden Wirtschaften, die aufeinander angewiesen sind und sich gegenseitig unterstützen sollen, noch gegeneinanderarbeiten. Unsere Fraktion vermißt einen solchen grundlegenden und weitsichtigen Plan, der es uns ermöglicht, festzustellen, ob und in welcher Weise das dahin geschickte Geld auch produktiv wirkt und den größten Nutzeffekt für beide Teile, für den gebenden und den nehmenden Teil, gewährleistet.\n",
      "Nebenbei bemerkt würde ein solcher Plan sowohl über die Ausgaben wie über die Einnahmen geeignet sein, die Augen der Welt einmal darauf zu lenken, daß die Unterstützung von Berlin nicht allein Sache Westdeutschlands sein darf. In erster Linie ist es natürlich unsere Angelegenheit, da die Berliner Brüder unseres Volkes sind, die wegen ihrer und unserer Freiheit leiden. Zum andern ist es aber nicht allein unsere Schuld, daß diese Situation besteht. An den Reibungen unter\n",
      "\n",
      "({0})\n",
      "den Alliierten sind die Deutschen nicht schuld. Deswegen müssen wir durch die Darlegung der Vernünftigkeit unserer Maßnahmen und durch den Hinweis darauf, daß wir bis an das Äußerste unserer Leistungsfähigkeit gegangen sind und uns hinsichtlich unserer Leistungen auch nicht selber überziehen dürfen, die Welt für den Gedanken erwärmen, daß die Unterstützung von Berlin eine Angelegenheit der Weltöffentlichkeit und nicht nur eine deutsche Angelegenheit ist.\n",
      "({1})\n",
      "\n",
      "Extraktive Zusammenfassung:  Das ist aber nur die eine Seite.Wichtiger scheint mir die andere Seite zu sein.Deswegen müssen wir durch die Darlegung der Vernünftigkeit unserer Maßnahmen und durch den Hinweis darauf, daß wir bis an das Äußerste unserer Leistungsfähigkeit gegangen sind und uns hinsichtlich unserer Leistungen auch nicht selber überziehen dürfen, die Welt für den Gedanken erwärmen, daß die Unterstützung von Berlin eine Angelegenheit der Weltöffentlichkeit und nicht nur eine deutsche Angelegenheit ist.\n",
      "\n",
      "Abstraktive Zusammenfassung:  [{'summary_text': 'In seiner Rede betont der Redner die Notwendigkeit einer einheitlichen, großzügigen Plan zur Unterstützung der kämpfenden Berliner Bevölkerung. Er hebt hervor, dass die Arbeitslosigkeit eine Angelegenheit ist, die im Westen bei 1,8 Millionen direkt Betroffenen hervorruft. Zudem kritisiert er die Bedeutung eines umfassenden Planes für die Reorganisation der Berliner Wirtschaft und die Abstimmung ihrer Leistungen mit den Bedürfnissen des Westens. Der Redner betont, dass ein solcher Plan nicht alleine Verantwortung für die Unterstützung von Berlin tragen muss, um die ußerungen zu korrigieren und fordert eine einheitliche Zusammenarbeit zwischen Deutschland und Deutschland. Er warnt vor der Gefahr, dass es nicht nur in Deutschland angesiedelt ist, sondern auch in der Lage ist, sich gegenseitig zu verhalten, und betont die Bedeutung der Unterstützung der Deutschen, die die Flüchtlinge und die Auswirkungen auf die Bevölkerung hat, insbesondere in der Reibungen, er fordert ein umfassendes Plan, der die Unterstützung der Welt für die Zukunft zu gewährleisten.'}]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "a6d25c4d-cd21-4225-b019-9a32ac420e74",
   "metadata": {},
   "source": [
    "## Fazit\n",
    "\n",
    "Zu Beginn des Projekts hatten wir große Schwierigkeiten und mussten viel recherchieren, um die notwendigen Kenntnisse zu erhalten. Eine der größten Herausforderungen war die Datenbeschaffung, da wir keinen Datensatz finden konnten, der eine Referenzzusammenfassung enthielt. Dadurch mussten wir uns eigene Daten zusammenstellen, was den gesamten Prozess deutlich komplizierter machte. Zudem bemerkten wir, dass die Menge der verfügbaren Daten nicht ausreichte, um die Modelle effektiv nach unseren Vorstellungen zu trainieren. Dies wirkte sich etwas auf die Qualität der Ergebnisse aus, insbesondere da die Qualität der generierten Referenzzusammenfassungen den Erfolg des Fine-Tunings beeinflusste.\n",
    "\n",
    "Trotz dieser Probleme haben wir im Verlauf des Projekts eine Menge gelernt und wichtige Erfahrungen gesammelt. Besonders im Bereich der Textzusammenfassung, beim Fine-Tuning von Modellen und bei der Aufbereitung von Daten konnten wir unser Wissen erweitern. Obwohl es nicht ganz unseren ursprünglichen Vorstellungen eines deutlich genaueren und präziseren Summarizers entsprach, haben uns die Herausforderungen geholfen, besser zu verstehen wie wichtig gute Datensätze sind, um wirklich gute Ergebnisse zu erzielen."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Quellen\n",
    "\n",
    "- [Two minutes NLP — Learn the ROUGE metric by examples](https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499)\n",
    "- [Understanding BLEU and ROUGE score for NLP evaluation](https://medium.com/@sthanikamsanthosh1994/understanding-bleu-and-rouge-score-for-nlp-evaluation-1ab334ecadcb)\n",
    "- [Extractive vs. Abstractive Summarization](https://www.prodigaltech.com/blog/extractive-vs-abstractive-summarization-how-does-it-work#foldMain)\n",
    "- [Fine-tune a pretrained model](https://huggingface.co/docs/transformers/en/training)\n",
    "- [How to Calculate ROUGE Score in Python](https://thepythoncode.com/article/calculate-rouge-score-in-python#setting-up-the-environment-for-python-implementation)"
   ],
   "id": "6a7c791106f112a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55772e6-278b-431f-b0a3-9e9e317aa50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
